arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 2.17.0
--------------------
git hash: b'09689915bf7f15f1b69e4770c3af880012ec7c46'
--------------------
b'diff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035091760_ddbcd2b4c1966b406c280af504c43240.png b/Dataset/FaceData/processed/Bui Van Du/z5840035091760_ddbcd2b4c1966b406c280af504c43240.png\ndeleted file mode 100644\nindex 55d135a..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035091760_ddbcd2b4c1966b406c280af504c43240.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035102428_6cb02a50874c096d7e869f359e6e9f44.png b/Dataset/FaceData/processed/Bui Van Du/z5840035102428_6cb02a50874c096d7e869f359e6e9f44.png\ndeleted file mode 100644\nindex 5870c9b..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035102428_6cb02a50874c096d7e869f359e6e9f44.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035105367_56e86e7059316e567e1245cb1ba5184b.png b/Dataset/FaceData/processed/Bui Van Du/z5840035105367_56e86e7059316e567e1245cb1ba5184b.png\ndeleted file mode 100644\nindex a640c28..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035105367_56e86e7059316e567e1245cb1ba5184b.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035111992_4296b2fc8aaa594fcd211e2010e620b6.png b/Dataset/FaceData/processed/Bui Van Du/z5840035111992_4296b2fc8aaa594fcd211e2010e620b6.png\ndeleted file mode 100644\nindex 4beabd6..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035111992_4296b2fc8aaa594fcd211e2010e620b6.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035120922_0532ace7ffc6009d2c56531ddc16c709.png b/Dataset/FaceData/processed/Bui Van Du/z5840035120922_0532ace7ffc6009d2c56531ddc16c709.png\ndeleted file mode 100644\nindex f75225a..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035120922_0532ace7ffc6009d2c56531ddc16c709.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035122579_5e19bfa1940d85292819aeab30327d4f.png b/Dataset/FaceData/processed/Bui Van Du/z5840035122579_5e19bfa1940d85292819aeab30327d4f.png\ndeleted file mode 100644\nindex 40fbd9b..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035122579_5e19bfa1940d85292819aeab30327d4f.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Bui Van Du/z5840035135421_58ba6e3589fe8aac502f330f46cdd791.png b/Dataset/FaceData/processed/Bui Van Du/z5840035135421_58ba6e3589fe8aac502f330f46cdd791.png\ndeleted file mode 100644\nindex c684ac2..0000000\nBinary files a/Dataset/FaceData/processed/Bui Van Du/z5840035135421_58ba6e3589fe8aac502f330f46cdd791.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930698451_b7952a0f427a5b1b6aa3891eae6f1201.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930698451_b7952a0f427a5b1b6aa3891eae6f1201.png\ndeleted file mode 100644\nindex 12ab17d..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930698451_b7952a0f427a5b1b6aa3891eae6f1201.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930698549_a96195143d9b670b1cf37a73eb06bc3f.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930698549_a96195143d9b670b1cf37a73eb06bc3f.png\ndeleted file mode 100644\nindex 0d9f42f..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930698549_a96195143d9b670b1cf37a73eb06bc3f.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930708284_e11bf131837eba28a769df4ad62d83ca.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930708284_e11bf131837eba28a769df4ad62d83ca.png\ndeleted file mode 100644\nindex ccccd9d..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930708284_e11bf131837eba28a769df4ad62d83ca.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930710448_cc1f9fde9d11d9f66e31bfa6ca8b288c.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930710448_cc1f9fde9d11d9f66e31bfa6ca8b288c.png\ndeleted file mode 100644\nindex 41515ca..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930710448_cc1f9fde9d11d9f66e31bfa6ca8b288c.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930723230_688117e0f10ee4d293d10783fac15170.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930723230_688117e0f10ee4d293d10783fac15170.png\ndeleted file mode 100644\nindex 4a15656..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930723230_688117e0f10ee4d293d10783fac15170.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930775533_f586f5af910744a62899d3b3d2a33789.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930775533_f586f5af910744a62899d3b3d2a33789.png\ndeleted file mode 100644\nindex f52c8a4..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930775533_f586f5af910744a62899d3b3d2a33789.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930777855_24f31c113c641bb3364d5d97feb31b3c.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930777855_24f31c113c641bb3364d5d97feb31b3c.png\ndeleted file mode 100644\nindex 466d140..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930777855_24f31c113c641bb3364d5d97feb31b3c.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930778549_305cf7d0cc31167ab554b790e62a7edc.png b/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930778549_305cf7d0cc31167ab554b790e62a7edc.png\ndeleted file mode 100644\nindex 2e39b64..0000000\nBinary files a/Dataset/FaceData/processed/Nguyen Van Phu Qui/z5839930778549_305cf7d0cc31167ab554b790e62a7edc.png and /dev/null differ\ndiff --git a/Dataset/FaceData/processed/bounding_boxes_05408.txt b/Dataset/FaceData/processed/bounding_boxes_05408.txt\ndeleted file mode 100644\nindex d87685c..0000000\n--- a/Dataset/FaceData/processed/bounding_boxes_05408.txt\n+++ /dev/null\n@@ -1,8 +0,0 @@\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930723230_688117e0f10ee4d293d10783fac15170.png 217 657 933 1605\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930777855_24f31c113c641bb3364d5d97feb31b3c.png 287 655 1045 1723\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930698549_a96195143d9b670b1cf37a73eb06bc3f.png 276 408 1185 1720\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930710448_cc1f9fde9d11d9f66e31bfa6ca8b288c.png 257 536 1165 1769\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930775533_f586f5af910744a62899d3b3d2a33789.png 364 721 1057 1697\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930708284_e11bf131837eba28a769df4ad62d83ca.png 277 586 1038 1642\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930698451_b7952a0f427a5b1b6aa3891eae6f1201.png 341 818 966 1679\n-Dataset/FaceData/processed\\Nguyen Van Phu Qui\\z5839930778549_305cf7d0cc31167ab554b790e62a7edc.png 250 746 1069 1836\ndiff --git a/Dataset/FaceData/processed/bounding_boxes_73937.txt b/Dataset/FaceData/processed/bounding_boxes_73937.txt\ndeleted file mode 100644\nindex 506867f..0000000\n--- a/Dataset/FaceData/processed/bounding_boxes_73937.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035105367_56e86e7059316e567e1245cb1ba5184b.png 216 408 717 1070\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035091760_ddbcd2b4c1966b406c280af504c43240.png 239 374 720 1023\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035122579_5e19bfa1940d85292819aeab30327d4f.png 215 368 690 1014\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035102428_6cb02a50874c096d7e869f359e6e9f44.png 240 361 706 1016\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035135421_58ba6e3589fe8aac502f330f46cdd791.png 239 369 721 1032\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035120922_0532ace7ffc6009d2c56531ddc16c709.png 155 367 655 1059\n-Dataset/FaceData/processed\\Bui Van Du\\z5840035111992_4296b2fc8aaa594fcd211e2010e620b6.png 232 359 682 950\ndiff --git a/Dataset/FaceData/processed/revision_info.txt b/Dataset/FaceData/processed/revision_info.txt\ndeleted file mode 100644\nindex 8ca90d1..0000000\n--- a/Dataset/FaceData/processed/revision_info.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\n---------------------\n-tensorflow version: 2.17.0\n---------------------\n-git hash: b\'\'\n---------------------\n-b\'\'\n\\ No newline at end of file\ndiff --git a/README.md b/README.md\nindex c79d259..e89e47d 100644\nBinary files a/README.md and b/README.md differ\ndiff --git a/requirements.txt b/requirements.txt\nindex aa078a0..e6d121b 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -7,4 +7,7 @@ matplotlib\n Pillow\n requests\n psutil\n-imageio\n\\ No newline at end of file\n+imageio\n+flask-cors \n+mysql-connector-python\n+\ndiff --git a/src/align/__pycache__/detect_face.cpython-39.pyc b/src/align/__pycache__/detect_face.cpython-39.pyc\nindex ff60f77..1e42791 100644\nBinary files a/src/align/__pycache__/detect_face.cpython-39.pyc and b/src/align/__pycache__/detect_face.cpython-39.pyc differ\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\nindex 2300ff3..e47af9a 100644\n--- a/src/align/detect_face.py\n+++ b/src/align/detect_face.py\n@@ -1,27 +1,5 @@\n-""" Tensorflow implementation of the face detection / alignment algorithm found at\n-https://github.com/kpzhang93/MTCNN_face_detection_alignment\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n+#    - \xc4\x90\xc3\xa2y l\xc3\xa0 file Python ch\xe1\xbb\xa9a m\xc3\xa3 ngu\xe1\xbb\x93n \xc4\x91\xe1\xbb\x83 ph\xc3\xa1t hi\xe1\xbb\x87n khu\xc3\xb4n m\xe1\xba\xb7t s\xe1\xbb\xad d\xe1\xbb\xa5ng m\xc3\xb4 h\xc3\xacnh MTCNN (Multi-task Cascaded Convolutional Networks)\n+#    - N\xc3\xb3 ch\xe1\xbb\xa9a c\xc3\xa1c h\xc3\xa0m v\xc3\xa0 l\xe1\xbb\x9bp c\xe1\xba\xa7n thi\xe1\xba\xbft \xc4\x91\xe1\xbb\x83 ph\xc3\xa1t hi\xe1\xbb\x87n v\xc3\xa0 x\xc3\xa1c \xc4\x91\xe1\xbb\x8bnh v\xe1\xbb\x8b tr\xc3\xad khu\xc3\xb4n m\xe1\xba\xb7t trong h\xc3\xacnh \xe1\xba\xa3nh.\n \n from __future__ import absolute_import\n from __future__ import division\n@@ -34,7 +12,7 @@ import tensorflow as tf\n import cv2\n import os\n \n-def layer(op):\n+def layer(op): # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a decorator layer \xc4\x91\xe1\xbb\x83 t\xe1\xba\xa1o c\xc3\xa1c l\xe1\xbb\x9bp m\xe1\xba\xa1ng neural\n     """Decorator for composable network layers."""\n \n     def layer_decorated(self, *args, **kwargs):\n@@ -58,7 +36,7 @@ def layer(op):\n \n     return layer_decorated\n \n-class Network(object):\n+class Network(object): # L\xe1\xbb\x9bp c\xc6\xa1 s\xe1\xbb\x9f cho c\xc3\xa1c m\xe1\xba\xa1ng neural\n \n     def __init__(self, inputs, trainable=True):\n         # The input nodes for this network\n@@ -128,6 +106,7 @@ class Network(object):\n         """Verifies that the padding is one of the supported ones."""\n         assert padding in (\'SAME\', \'VALID\')\n \n+    # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a ph\xc6\xb0\xc6\xa1ng th\xe1\xbb\xa9c conv \xc4\x91\xe1\xbb\x83 th\xe1\xbb\xb1c hi\xe1\xbb\x87n ph\xc3\xa9p t\xc3\xadnh convolution tr\xc3\xaan d\xe1\xbb\xaf li\xe1\xbb\x87u \xc4\x91\xe1\xba\xa7u v\xc3\xa0o\n     @layer\n     def conv(self,\n              inp,\n@@ -163,6 +142,8 @@ class Network(object):\n                 output = tf.nn.relu(output, name=scope.name)\n             return output\n \n+\n+    # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a ph\xc6\xb0\xc6\xa1ng th\xe1\xbb\xa9c prelu \xc4\x91\xe1\xbb\x83 th\xe1\xbb\xb1c hi\xe1\xbb\x87n ph\xc3\xa9p t\xc3\xadnh PReLU (Parametric ReLU) tr\xc3\xaan d\xe1\xbb\xaf li\xe1\xbb\x87u \xc4\x91\xe1\xba\xa7u v\xc3\xa0o\n     @layer\n     def prelu(self, inp, name):\n         with tf.compat.v1.variable_scope(name):\n@@ -171,8 +152,11 @@ class Network(object):\n             output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n         return output\n \n+    # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a ph\xc6\xb0\xc6\xa1ng th\xe1\xbb\xa9c max_pool \xc4\x91\xe1\xbb\x83 th\xe1\xbb\xb1c hi\xe1\xbb\x87n ph\xc3\xa9p t\xc3\xadnh max pooling tr\xc3\xaan d\xe1\xbb\xaf li\xe1\xbb\x87u \xc4\x91\xe1\xba\xa7u v\xc3\xa0o\n     @layer\n     def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding=\'SAME\'):\n+        \n+        # C\xc3\xa1c l\xe1\xbb\x9bp PNet, RNet, ONet: \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a c\xe1\xba\xa5u tr\xc3\xbac c\xe1\xbb\xa7a ba m\xe1\xba\xa1ng trong MTCNN\n         self.validate_padding(padding)\n         return tf.nn.max_pool(inp,\n                               ksize=[1, k_h, k_w, 1],\n@@ -180,6 +164,7 @@ class Network(object):\n                               padding=padding,\n                               name=name)\n \n+    # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a ph\xc6\xb0\xc6\xa1ng th\xe1\xbb\xa9c fc \xc4\x91\xe1\xbb\x83 th\xe1\xbb\xb1c hi\xe1\xbb\x87n ph\xc3\xa9p t\xc3\xadnh fully connected tr\xc3\xaan d\xe1\xbb\xaf li\xe1\xbb\x87u \xc4\x91\xe1\xba\xa7u v\xc3\xa0o\n     @layer\n     def fc(self, inp, num_out, name, relu=True):\n         with tf.compat.v1.variable_scope(name):\n@@ -205,6 +190,7 @@ class Network(object):\n     compute softmax along the dimension of target\n     the native softmax only supports batch_size x dimension\n     """\n+    # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a ph\xc6\xb0\xc6\xa1ng th\xe1\xbb\xa9c softmax \xc4\x91\xe1\xbb\x83 th\xe1\xbb\xb1c hi\xe1\xbb\x87n ph\xc3\xa9p t\xc3\xadnh softmax tr\xc3\xaan d\xe1\xbb\xaf li\xe1\xbb\x87u \xc4\x91\xe1\xba\xa7u v\xc3\xa0o\n     @layer\n     def softmax(self, target, axis, name=None):\n         max_axis = tf.reduce_max(target, axis, keepdims=True)\n@@ -213,7 +199,9 @@ class Network(object):\n         softmax = tf.compat.v1.div(target_exp, normalize, name)\n         return softmax\n     \n-class PNet(Network):\n+    \n+\n+class PNet(Network): # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a l\xe1\xbb\x9bp PNet k\xe1\xba\xbf th\xe1\xbb\xaba t\xe1\xbb\xab l\xe1\xbb\x9bp Network\n     def setup(self):\n         (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n              .conv(3, 3, 10, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n@@ -226,10 +214,11 @@ class PNet(Network):\n              .conv(1, 1, 2, 1, 1, relu=False, name=\'conv4-1\')\n              .softmax(3,name=\'prob1\'))\n \n+        # \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a c\xc3\xa1c l\xe1\xbb\x9bp trong m\xe1\xba\xa1ng PNet\n         (self.feed(\'PReLU3\') #pylint: disable=no-value-for-parameter\n              .conv(1, 1, 4, 1, 1, relu=False, name=\'conv4-2\'))\n         \n-class RNet(Network):\n+class RNet(Network): # H\xc3\xa0m create_mtcnn: T\xe1\xba\xa1o v\xc3\xa0 t\xe1\xba\xa3i c\xc3\xa1c m\xc3\xb4 h\xc3\xacnh MTCNN\n     def setup(self):\n         (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n              .conv(3, 3, 28, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n@@ -248,7 +237,7 @@ class RNet(Network):\n         (self.feed(\'prelu4\') #pylint: disable=no-value-for-parameter\n              .fc(4, relu=False, name=\'conv5-2\'))\n \n-class ONet(Network):\n+class ONet(Network): \n     def setup(self):\n         (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n              .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n@@ -272,7 +261,8 @@ class ONet(Network):\n \n         (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n              .fc(10, relu=False, name=\'conv6-3\'))\n-\n+        \n+# H\xc3\xa0m create_mtcnn: T\xe1\xba\xa1o v\xc3\xa0 t\xe1\xba\xa3i c\xc3\xa1c m\xc3\xb4 h\xc3\xacnh MTCNN\n def create_mtcnn(sess, model_path):\n     if not model_path:\n         model_path,_ = os.path.split(os.path.realpath(__file__))\n@@ -295,7 +285,7 @@ def create_mtcnn(sess, model_path):\n     onet_fun = lambda img : sess.run((\'onet/conv6-2/conv6-2:0\', \'onet/conv6-3/conv6-3:0\', \'onet/prob1:0\'), feed_dict={\'onet/input:0\':img})\n     return pnet_fun, rnet_fun, onet_fun\n \n-def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n+def detect_face(img, minsize, pnet, rnet, onet, threshold, factor): # H\xc3\xa0m ch\xc3\xadnh \xc4\x91\xe1\xbb\x83 ph\xc3\xa1t hi\xe1\xbb\x87n khu\xc3\xb4n m\xe1\xba\xb7t trong \xe1\xba\xa3nh\n     """Detects faces in an image, and returns bounding boxes and points for them.\n     img: input image\n     minsize: minimum faces\' size\n@@ -531,6 +521,8 @@ def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, thre\n     # second stage - refinement of face candidates with rnet\n     # # # # # # # # # # # # #\n \n+\n+# C\xc3\xa1c h\xc3\xa0m h\xe1\xbb\x97 tr\xe1\xbb\xa3 nh\xc6\xb0 bbreg, generateBoundingBox, nms, pad, rerec, imresample: Th\xe1\xbb\xb1c hi\xe1\xbb\x87n c\xc3\xa1c thao t\xc3\xa1c x\xe1\xbb\xad l\xc3\xbd h\xe1\xbb\x99p gi\xe1\xbb\x9bi h\xe1\xba\xa1n v\xc3\xa0 \xe1\xba\xa3nh\n     bulk_rnet_input = np.empty((0, 24, 24, 3))\n     for index, image_obj in enumerate(images_with_boxes):\n         if \'rnet_input\' in image_obj:\ndiff --git a/src/calculate_filtering_metrics.py b/src/calculate_filtering_metrics.py\nindex f60b9ae..5899ea1 100644\n--- a/src/calculate_filtering_metrics.py\n+++ b/src/calculate_filtering_metrics.py\n@@ -1,26 +1,23 @@\n-"""Calculate filtering metrics for a dataset and store in a .hdf file.\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n+# 1. X\xe1\xbb\xad l\xc3\xbd d\xe1\xbb\xaf li\xe1\xbb\x87u khu\xc3\xb4n m\xe1\xba\xb7t:\n+#    - \xc4\x90\xe1\xbb\x8dc t\xe1\xba\xadp d\xe1\xbb\xaf li\xe1\xbb\x87u h\xc3\xacnh \xe1\xba\xa3nh khu\xc3\xb4n m\xe1\xba\xb7t t\xe1\xbb\xab th\xc6\xb0 m\xe1\xbb\xa5c \xc4\x91\xc6\xb0\xe1\xbb\xa3c ch\xe1\xbb\x89 \xc4\x91\xe1\xbb\x8bnh.\n+#    - S\xe1\xbb\xad d\xe1\xbb\xa5ng m\xe1\xbb\x99t m\xc3\xb4 h\xc3\xacnh \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c hu\xe1\xba\xa5n luy\xe1\xbb\x87n tr\xc6\xb0\xe1\xbb\x9bc (pretrained model) \xc4\x91\xe1\xbb\x83 t\xe1\xba\xa1o ra c\xc3\xa1c embedding cho m\xe1\xbb\x97i h\xc3\xacnh \xe1\xba\xa3nh khu\xc3\xb4n m\xe1\xba\xb7t.\n+\n+# 2. T\xc3\xadnh to\xc3\xa1n c\xc3\xa1c ch\xe1\xbb\x89 s\xe1\xbb\x91 l\xe1\xbb\x8dc:\n+#    - T\xc3\xadnh to\xc3\xa1n trung t\xc3\xa2m (center) cho m\xe1\xbb\x97i l\xe1\xbb\x9bp (m\xe1\xbb\x97i ng\xc6\xb0\xe1\xbb\x9di) trong kh\xc3\xb4ng gian embedding.\n+#    - T\xc3\xadnh kho\xe1\xba\xa3ng c\xc3\xa1ch t\xe1\xbb\xab m\xe1\xbb\x97i embedding \xc4\x91\xe1\xba\xbfn trung t\xc3\xa2m c\xe1\xbb\xa7a l\xe1\xbb\x9bp t\xc6\xb0\xc6\xa1ng \xe1\xbb\xa9ng.\n+\n+# 3. \xc4\x90\xc3\xa1nh gi\xc3\xa1 ch\xe1\xba\xa5t l\xc6\xb0\xe1\xbb\xa3ng d\xe1\xbb\xaf li\xe1\xbb\x87u:\n+#    - S\xe1\xbb\xad d\xe1\xbb\xa5ng c\xc3\xa1c ch\xe1\xbb\x89 s\xe1\xbb\x91 \xc4\x91\xc3\xa3 t\xc3\xadnh to\xc3\xa1n \xc4\x91\xe1\xbb\x83 \xc4\x91\xc3\xa1nh gi\xc3\xa1 ch\xe1\xba\xa5t l\xc6\xb0\xe1\xbb\xa3ng c\xe1\xbb\xa7a c\xc3\xa1c h\xc3\xacnh \xe1\xba\xa3nh trong dataset.\n+#    - \xc4\x90i\xe1\xbb\x81u n\xc3\xa0y c\xc3\xb3 th\xe1\xbb\x83 gi\xc3\xbap x\xc3\xa1c \xc4\x91\xe1\xbb\x8bnh c\xc3\xa1c h\xc3\xacnh \xe1\xba\xa3nh kh\xc3\xb4ng ph\xc3\xb9 h\xe1\xbb\xa3p ho\xe1\xba\xb7c c\xc3\xb3 ch\xe1\xba\xa5t l\xc6\xb0\xe1\xbb\xa3ng k\xc3\xa9m.\n+\n+# 4. L\xc6\xb0u tr\xe1\xbb\xaf k\xe1\xba\xbft qu\xe1\xba\xa3:\n+#    - Ghi c\xc3\xa1c th\xc3\xb4ng tin \xc4\x91\xc3\xa3 t\xc3\xadnh to\xc3\xa1n v\xc3\xa0o m\xe1\xbb\x99t file HDF5, bao g\xe1\xbb\x93m t\xc3\xaan l\xe1\xbb\x9bp, danh s\xc3\xa1ch h\xc3\xacnh \xe1\xba\xa3nh, danh s\xc3\xa1ch nh\xc3\xa3n v\xc3\xa0 kho\xe1\xba\xa3ng c\xc3\xa1ch \xc4\x91\xe1\xba\xbfn trung t\xc3\xa2m.\n+\n+# 5. Ti\xe1\xbb\x81n x\xe1\xbb\xad l\xc3\xbd d\xe1\xbb\xaf li\xe1\xbb\x87u:\n+#    - Script n\xc3\xa0y c\xc3\xb3 th\xe1\xbb\x83 \xc4\x91\xc6\xb0\xe1\xbb\xa3c s\xe1\xbb\xad d\xe1\xbb\xa5ng nh\xc6\xb0 m\xe1\xbb\x99t c\xc3\xb4ng c\xe1\xbb\xa5 ti\xe1\xbb\x81n x\xe1\xbb\xad l\xc3\xbd \xc4\x91\xe1\xbb\x83 c\xe1\xba\xa3i thi\xe1\xbb\x87n ch\xe1\xba\xa5t l\xc6\xb0\xe1\xbb\xa3ng c\xe1\xbb\xa7a t\xe1\xba\xadp d\xe1\xbb\xaf li\xe1\xbb\x87u khu\xc3\xb4n m\xe1\xba\xb7t tr\xc6\xb0\xe1\xbb\x9bc khi s\xe1\xbb\xad d\xe1\xbb\xa5ng cho c\xc3\xa1c t\xc3\xa1c v\xe1\xbb\xa5 nh\xe1\xba\xadn d\xe1\xba\xa1ng khu\xc3\xb4n m\xe1\xba\xb7t.\n+\n+# Trong kh\xc3\xb4ng gian embedding, trung t\xc3\xa2m l\xc3\xa0 vector trung b\xc3\xacnh c\xe1\xbb\xa7a t\xe1\xba\xa5t c\xe1\xba\xa3 c\xc3\xa1c embedding thu\xe1\xbb\x99c c\xc3\xb9ng m\xe1\xbb\x99t l\xe1\xbb\x9bp (trong tr\xc6\xb0\xe1\xbb\x9dng h\xe1\xbb\xa3p n\xc3\xa0y l\xc3\xa0 c\xc3\xb9ng m\xe1\xbb\x99t ng\xc6\xb0\xe1\xbb\x9di).\n+# Embedding trong ng\xe1\xbb\xaf c\xe1\xba\xa3nh n\xc3\xa0y l\xc3\xa0 m\xe1\xbb\x99t vector s\xe1\xbb\x91 h\xe1\xbb\x8dc \xc4\x91\xe1\xba\xa1i di\xe1\xbb\x87n cho m\xe1\xbb\x99t h\xc3\xacnh \xe1\xba\xa3nh khu\xc3\xb4n m\xe1\xba\xb7t trong kh\xc3\xb4ng gian \xc4\x91a chi\xe1\xbb\x81u\n \n from __future__ import absolute_import\n from __future__ import division\n@@ -36,29 +33,35 @@ import time\n import h5py\n import math\n from tensorflow.python.platform import gfile\n-from six import iteritems\n+from six import iteritems # Kh\xe1\xbb\x9fi t\xe1\xba\xa1o embedding\n \n def main(args):\n-    dataset = facenet.get_dataset(args.dataset_dir)\n+    dataset = facenet.get_dataset(args.dataset_dir) # \xc4\x91\xe1\xbb\x8dc th\xc6\xb0 m\xe1\xbb\xa5c dataset\n+    # H\xc3\xa0m n\xc3\xa0y s\xe1\xba\xbd qu\xc3\xa9t qua t\xe1\xba\xa5t c\xe1\xba\xa3 c\xc3\xa1c th\xc6\xb0 m\xe1\xbb\xa5c con trong dataset_dir, m\xe1\xbb\x97i th\xc6\xb0 m\xe1\xbb\xa5c con \xc4\x91\xe1\xba\xa1i di\xe1\xbb\x87n cho m\xe1\xbb\x99t l\xe1\xbb\x9bp (trong tr\xc6\xb0\xe1\xbb\x9dng h\xe1\xbb\xa3p n\xc3\xa0y l\xc3\xa0 m\xe1\xbb\x99t ng\xc6\xb0\xe1\xbb\x9di).\n   \n-    with tf.Graph().as_default():\n+    # S\xe1\xbb\xad d\xe1\xbb\xa5ng Pretrained model 20180402-114759.pb \n+    with tf.Graph().as_default(): # K\xe1\xba\xbft qu\xe1\xba\xa3 tr\xe1\xba\xa3 v\xe1\xbb\x81 (dataset) s\xe1\xba\xbd l\xc3\xa0 m\xe1\xbb\x99t c\xe1\xba\xa5u tr\xc3\xbac d\xe1\xbb\xaf li\xe1\xbb\x87u ch\xe1\xbb\xa9a th\xc3\xb4ng tin v\xe1\xbb\x81 t\xe1\xba\xa5t c\xe1\xba\xa3 c\xc3\xa1c l\xe1\xbb\x9bp (ng\xc6\xb0\xe1\xbb\x9di) v\xc3\xa0 \xc4\x91\xc6\xb0\xe1\xbb\x9dng d\xe1\xba\xabn \xc4\x91\xe1\xba\xbfn c\xc3\xa1c h\xc3\xacnh \xe1\xba\xa3nh t\xc6\xb0\xc6\xa1ng \xe1\xbb\xa9ng.\n       \n-        # Get a list of image paths and their labels\n+        # \xc4\x90\xe1\xbb\x8dc v\xc3\xa0 x\xe1\xbb\xad l\xc3\xbd d\xe1\xbb\xaf li\xe1\xbb\x87u \xe1\xba\xa3nh\n         image_list, label_list = facenet.get_image_paths_and_labels(dataset)\n         nrof_images = len(image_list)\n         image_indices = range(nrof_images)\n \n+        # T\xe1\xba\xa3i m\xc3\xb4 h\xc3\xacnh \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c hu\xe1\xba\xa5n luy\xe1\xbb\x87n\n         image_batch, label_batch = facenet.read_and_augment_data(image_list,\n             image_indices, args.image_size, args.batch_size, None, \n             False, False, False, nrof_preprocess_threads=4, shuffle=False)\n-        \n         model_exp = os.path.expanduser(args.model_file)\n         with gfile.FastGFile(model_exp,\'rb\') as f:\n             graph_def = tf.GraphDef()\n+\n+            #L\xe1\xba\xa5y tensor embeddings\n             graph_def.ParseFromString(f.read())\n             input_map={\'input\':image_batch, \'phase_train\':False}\n+\n+            #T\xe1\xba\xa1o session TensorFlow v\xc3\xa0 th\xe1\xbb\xb1c hi\xe1\xbb\x87n t\xc3\xadnh to\xc3\xa1n\n             tf.import_graph_def(graph_def, input_map=input_map, name=\'net\')\n-        \n+\n         embeddings = tf.get_default_graph().get_tensor_by_name("net/embeddings:0")\n \n         with tf.Session() as sess:\n@@ -71,9 +74,13 @@ def main(args):\n             class_names = [cls.name for cls in dataset]\n             nrof_examples_per_class = [ len(cls.image_paths) for cls in dataset ]\n             class_variance = np.zeros((nrof_classes,))\n+\n+            # T\xc3\xadnh to\xc3\xa1n trung t\xc3\xa2m\n             class_center = np.zeros((nrof_classes,embedding_size))\n             distance_to_center = np.ones((len(label_list),))*np.NaN\n             emb_array = np.zeros((0,embedding_size))\n+\n+            # t\xc3\xadnh kho\xe1\xba\xa3ng c\xc3\xa1ch t\xe1\xbb\xab m\xe1\xbb\x97i embedding \xc4\x91\xe1\xba\xbfn trung t\xc3\xa2m\n             idx_array = np.zeros((0,), dtype=np.int32)\n             lab_array = np.zeros((0,), dtype=np.int32)\n             index_arr = np.append(0, np.cumsum(nrof_examples_per_class))\n@@ -89,26 +96,28 @@ def main(args):\n                         # We have calculated all the embeddings for this class\n                         i2 = np.argsort(idx_array[cls_idx])\n                         emb_class = emb_array[cls_idx,:]\n-                        emb_sort = emb_class[i2,:]\n-                        center = np.mean(emb_sort, axis=0)\n-                        diffs = emb_sort - center\n-                        dists_sqr = np.sum(np.square(diffs), axis=1)\n-                        class_variance[cls] = np.mean(dists_sqr)\n-                        class_center[cls,:] = center\n-                        distance_to_center[index_arr[cls]:index_arr[cls+1]] = np.sqrt(dists_sqr)\n-                        emb_array = np.delete(emb_array, cls_idx, axis=0)\n+                        emb_sort = emb_class[i2,:] # Ch\xe1\xbb\xa9a t\xe1\xba\xa5t c\xe1\xba\xa3 c\xc3\xa1c embedding c\xe1\xbb\xa7a m\xe1\xbb\x99t l\xe1\xbb\x9bp\n+                        center = np.mean(emb_sort, axis=0) # T\xc3\xadnh trung b\xc3\xacnh theo c\xe1\xbb\x99t, t\xe1\xba\xa1o ra m\xe1\xbb\x99t vector trung t\xc3\xa2m.\n+                        diffs = emb_sort - center # T\xc3\xadnh to\xc3\xa1n kho\xe1\xba\xa3ng c\xc3\xa1ch gi\xe1\xbb\xafa t\xe1\xbb\xabng embedding v\xc3\xa0 trung t\xc3\xa2m\n+                        dists_sqr = np.sum(np.square(diffs), axis=1) # T\xc3\xadnh to\xc3\xa1n kho\xe1\xba\xa3ng c\xc3\xa1ch b\xc3\xacnh ph\xc6\xb0\xc6\xa1ng\n+                        class_variance[cls] = np.mean(dists_sqr) # T\xc3\xadnh to\xc3\xa1n ph\xc6\xb0\xc6\xa1ng sai c\xe1\xbb\xa7a l\xe1\xbb\x9bp\n+                        class_center[cls,:] = center # L\xc6\xb0u tr\xe1\xbb\xaf trung t\xc3\xa2m c\xe1\xbb\xa7a l\xe1\xbb\x9bp\n+                        distance_to_center[index_arr[cls]:index_arr[cls+1]] = np.sqrt(dists_sqr) # L\xc6\xb0u tr\xe1\xbb\xaf kho\xe1\xba\xa3ng c\xc3\xa1ch \xc4\x91\xe1\xba\xbfn trung t\xc3\xa2m\n+                        emb_array = np.delete(emb_array, cls_idx, axis=0) # X\xc3\xb3a c\xc3\xa1c embedding c\xe1\xbb\xa7a l\xe1\xbb\x9bp \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c t\xc3\xadnh to\xc3\xa1n\n                         idx_array = np.delete(idx_array, cls_idx, axis=0)\n                         lab_array = np.delete(lab_array, cls_idx, axis=0)\n \n                         \n                 print(\'Batch %d in %.3f seconds\' % (i, time.time()-t))\n-                \n+\n+            # Ghi d\xe1\xbb\xaf li\xe1\xbb\x87u l\xe1\xbb\x8dc v\xc3\xa0o file\n             print(\'Writing filtering data to %s\' % args.data_file_name)\n             mdict = {\'class_names\':class_names, \'image_list\':image_list, \'label_list\':label_list, \'distance_to_center\':distance_to_center }\n             with h5py.File(args.data_file_name, \'w\') as f:\n                 for key, value in iteritems(mdict):\n                     f.create_dataset(key, data=value)\n-                        \n+\n+# \xc4\x90\xe1\xbb\x8bnh ngh\xc4\xa9a c\xc3\xa1c \xc4\x91\xe1\xbb\x91i s\xe1\xbb\x91 d\xc3\xb2ng l\xe1\xbb\x87nh                     \n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n     \n@@ -124,5 +133,6 @@ def parse_arguments(argv):\n         help=\'Number of images to process in a batch.\', default=90)\n     return parser.parse_args(argv)\n \n+# \xc4\x90i\xe1\xbb\x83m v\xc3\xa0o ch\xc6\xb0\xc6\xa1ng tr\xc3\xacnh\n if __name__ == \'__main__\':\n     main(parse_arguments(sys.argv[1:]))\ndiff --git a/src/face_rec.py b/src/face_rec.py\nindex b643763..f2d8087 100644\n--- a/src/face_rec.py\n+++ b/src/face_rec.py\n@@ -16,6 +16,7 @@ import numpy as np\n import cv2\n import collections\n from sklearn.svm import SVC\n+import mysql.connector\n \n \n def main():\n@@ -85,13 +86,13 @@ def main():\n                             bb[i][3] = det[i][3]\n \n                             # Cat phan khuon mat tim duoc\n-                            cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n-                            scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\n+                            cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :] # C\xe1\xba\xaft m\xe1\xbb\x99t ph\xe1\xba\xa7n c\xe1\xbb\xa7a h\xc3\xacnh \xe1\xba\xa3nh (ch\xe1\xbb\xa9a khu\xc3\xb4n m\xe1\xba\xb7t) t\xe1\xbb\xab khung h\xc3\xacnh (frame)\n+                            scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE), # Thay \xc4\x91\xe1\xbb\x95i k\xc3\xadch th\xc6\xb0\xe1\xbb\x9bc c\xe1\xbb\xa7a h\xc3\xacnh \xe1\xba\xa3nh khu\xc3\xb4n m\xe1\xba\xb7t \xc4\x91\xe1\xbb\x83 ph\xc3\xb9 h\xe1\xbb\xa3p v\xe1\xbb\x9bi k\xc3\xadch th\xc6\xb0\xe1\xbb\x9bc \xc4\x91\xe1\xba\xa7u v\xc3\xa0o m\xc3\xa0 m\xc3\xb4 h\xc3\xacnh y\xc3\xaau c\xe1\xba\xa7u.\n                                                 interpolation=cv2.INTER_CUBIC)\n-                            scaled = facenet.prewhiten(scaled)\n-                            scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n-                            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n-                            emb_array = sess.run(embeddings, feed_dict=feed_dict)\n+                            scaled = facenet.prewhiten(scaled) # Chu\xe1\xba\xa9n h\xc3\xb3a h\xc3\xacnh \xe1\xba\xa3nh tr\xc6\xb0\xe1\xbb\x9bc khi \xc4\x91\xc6\xb0a v\xc3\xa0o m\xc3\xb4 h\xc3\xacnh \xc4\x91\xe1\xbb\x83 c\xe1\xba\xa3i thi\xe1\xbb\x87n hi\xe1\xbb\x87u su\xe1\xba\xa5t\n+                            scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3) #Thay \xc4\x91\xe1\xbb\x95i h\xc3\xacnh d\xe1\xba\xa1ng c\xe1\xbb\xa7a \xe1\xba\xa3nh \xc4\x91\xe1\xbb\x83 ph\xc3\xb9 h\xe1\xbb\xa3p v\xe1\xbb\x9bi \xc4\x91\xe1\xba\xa7u v\xc3\xa0o c\xe1\xbb\xa7a m\xc3\xb4 h\xc3\xacnh h\xe1\xbb\x8dc s\xc3\xa2u\n+                            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False} # Chu\xe1\xba\xa9n b\xe1\xbb\x8b d\xe1\xbb\xaf li\xe1\xbb\x87u \xc4\x91\xe1\xba\xa7u v\xc3\xa0o cho m\xc3\xb4 h\xc3\xacnh\n+                            emb_array = sess.run(embeddings, feed_dict=feed_dict) # Ch\xe1\xba\xa1y m\xc3\xb4 h\xc3\xacnh \xc4\x91\xe1\xbb\x83 t\xc3\xadnh to\xc3\xa1n embedding c\xe1\xbb\xa7a khu\xc3\xb4n m\xe1\xba\xb7t\n                             \n                             # Dua vao model de classifier\n                             predictions = model.predict_proba(emb_array)\n@@ -122,6 +123,9 @@ def main():\n                                         cv2.FONT_HERSHEY_COMPLEX_SMALL,\n                                         1, (255, 255, 255), thickness=1, lineType=2)\n                             person_detected[best_name] += 1\n+\n+                            # L\xc6\xb0u embedding v\xc3\xa0o c\xc6\xa1 s\xe1\xbb\x9f d\xe1\xbb\xaf li\xe1\xbb\x87u\n+                            save_embedding(name, emb_array)\n                 except:\n                     pass\n \n@@ -134,4 +138,32 @@ def main():\n             cv2.destroyAllWindows()\n \n \n+def save_embedding(name, embedding):\n+    try:\n+        # K\xe1\xba\xbft n\xe1\xbb\x91i \xc4\x91\xe1\xba\xbfn c\xc6\xa1 s\xe1\xbb\x9f d\xe1\xbb\xaf li\xe1\xbb\x87u MySQL\n+        connection = mysql.connector.connect(\n+            host=\'localhost\',\n+            user=\'root\',  \n+            # password=\'your_password\',  \n+            database=\'face_recognition\'\n+        )\n+        \n+        cursor = connection.cursor()\n+        \n+        # Chuy\xe1\xbb\x83n \xc4\x91\xe1\xbb\x95i embedding th\xc3\xa0nh \xc4\x91\xe1\xbb\x8bnh d\xe1\xba\xa1ng bytes\n+        embedding_bytes = embedding.tobytes()\n+        \n+        # L\xc6\xb0u th\xc3\xb4ng tin sinh vi\xc3\xaan v\xc3\xa0 embedding v\xc3\xa0o c\xc6\xa1 s\xe1\xbb\x9f d\xe1\xbb\xaf li\xe1\xbb\x87u\n+        cursor.execute("INSERT INTO students (name, embedding) VALUES (%s, %s)", (name, embedding_bytes))\n+        \n+        # Cam k\xe1\xba\xbft thay \xc4\x91\xe1\xbb\x95i\n+        connection.commit()\n+        \n+    except mysql.connector.Error as err:\n+        print("Error: {}".format(err))\n+    finally:\n+        cursor.close()\n+        connection.close()\n+\n+\n main()'